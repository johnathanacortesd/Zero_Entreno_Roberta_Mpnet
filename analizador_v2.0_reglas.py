!pip install -q torch transformers sentence-transformers pandas openpyxl tqdm scikit-learn 2>/dev/null

import os, re, time, torch
import numpy as np
import pandas as pd
import warnings
from tqdm.auto import tqdm
from sentence_transformers import SentenceTransformer
from collections import defaultdict
from google.colab import files

warnings.filterwarnings("ignore")

# ==================== CONFIGURACIÃ“N ====================
device = "cuda" if torch.cuda.is_available() else "cpu"
print(f"ğŸš€ Dispositivo: {device.upper()}")

# Modelo multilingÃ¼e con licencia Apache 2.0
embedder = SentenceTransformer("intfloat/multilingual-e5-large", device=device)

# ==================== REGLAS MEJORADAS ====================
POSITIVE_VERBS_CLIENT = [
    "confirma", "anuncia", "inaugura", "lanza", "lidera", "impulsa", "acompaÃ±a","continua",
    "gestiona", "acompaÃ±a", "otorga", "destina", "facilita", "apoya", "confirma","recibe",
    "reconoce", "homenajea", "firma", "inicia", "invierte", "entrega", "adelanta","demuestra",
    "presenta", "logra", "avanza", "atiende", "visita", "verifica","continÃºa","intensifica",
    "construye", "desarrolla", "fortalece", "promueve", "garantiza","expresa",
]

# Contextos que indican gestiÃ³n POSITIVA del cliente
POSITIVE_CONTEXTS = [
    "todo estÃ¡ listo", "obras de", "inversiÃ³n en","recibe distinciÃ³n",
    "mejoras en", "avance en", "beneficio", "articulaciÃ³n","expresa solidaridad",
    "liderazgo del", "bajo el liderazgo", "gracias a la alcaldÃ­a",
    "gracias al alcalde", "proyecto es posible gracias",
    "gestiÃ³n de", "gestiÃ³n del alcalde"
]

# Logros de programas/proyectos que implican gestiÃ³n positiva
ACHIEVEMENT_INDICATORS = [
    "bachilleres inician", "bachilleres se han inscrito", "estudiantes inician",
    "familias beneficiadas", "viviendas entregadas", "obras culminadas",
    "proyectos en marcha", "inversiÃ³n de", "beneficiarios",
    "acceso a", "programas profesionales", "vida universitaria"
]

# Palabras que indican acciones REACTIVAS (neutras, no gestiÃ³n)
NEUTRAL_REACTIONS = [
    "lamenta", "rechaza", "condena", "expresa solidaridad",
    "pide", "solicita", "exige", "manifesta preocupaciÃ³n"
]

# Contextos claramente negativos
NEGATIVE_TRIGGERS = [
    "escÃ¡ndalo", "corrupciÃ³n", "investigan al", "denuncian al",
    "irregularidad", "desfalco", "acusan", "protesta contra",
    "demanda contra", "sancionan", "fraude", "malversaciÃ³n"
]

TOPICS_KEYWORDS = {
    "Infraestructura": ["escenario", "multideportivo", "obra", "infraestructura", "vÃ­a", "parque",
                        "pavimentaciÃ³n", "construcciÃ³n", "puente", "polideportivo", "cancha"],
    "EducaciÃ³n": ["educaciÃ³n", "bachilleres", "universitaria", "colegio", "becas", "estudiantes",
                  "escuela", "universidad", "educaciÃ³n superior", "acceso a la universidad"],
    "Seguridad y Justicia": ["policÃ­a", "seguridad", "auxiliares", "dotaciÃ³n", "homicidio",
                            "delincuencia", "crimen", "atentado", "fallecimiento"],
    "Relaciones Internacionales": ["embajador", "cumbre", "celac", "diplomÃ¡tico", "internacional", "bilateral"],
    "CorrupciÃ³n y EscÃ¡ndalos": ["escÃ¡ndalo", "corrupciÃ³n", "investigan al", "denuncia contra", "fraude"],
    "Salud": ["salud", "hospital", "mÃ©dico", "atenciÃ³n mÃ©dica", "vacunaciÃ³n", "pandemia"],
    "Medio Ambiente": ["lluvias", "inundaciones", "emergencia", "clima", "ambiental", "desastre natural",
                      "huracÃ¡n", "afectados", "coletazo"],
    "EconomÃ­a": ["economÃ­a", "empleo", "empresa", "comercio", "inversiÃ³n econÃ³mica", "presupuesto"],
}

# ==================== FUNCIONES CORREGIDAS ====================

def normalize_text(text):
    """Normaliza texto removiendo artÃ­culos y preposiciones para mejor clustering"""
    # Convertir a minÃºsculas
    t = text.lower()

    # Remover artÃ­culos y preposiciones comunes
    stopwords = ['el', 'la', 'los', 'las', 'un', 'una', 'unos', 'unas',
                 'de', 'del', 'en', 'para', 'por', 'con', 'sin', 'sobre',
                 'que', 'todo', 'estÃ¡', 'son', 'es']

    # Mantener solo caracteres alfanumÃ©ricos y espacios
    t = re.sub(r'[^\wÃ¡Ã©Ã­Ã³ÃºÃ±\s]', ' ', t)
    t = re.sub(r'\s+', ' ', t).strip()

    # Remover stopwords
    words = t.split()
    words = [w for w in words if w not in stopwords and len(w) > 2]

    return " ".join(words)

def get_signature(text, words=20):
    """Genera firma textual normalizada para clustering"""
    normalized = normalize_text(text)
    # Tomar mÃ¡s palabras para capturar mejor la similitud
    return " ".join(normalized.split()[:words])

def universal_cluster(texts):
    """Clustering REAL - noticias similares tendrÃ¡n mismo tema/tono"""
    print("ğŸ“Š Agrupando noticias similares...")
    groups = defaultdict(list)

    for i, t in enumerate(texts):
        signature = get_signature(t)
        groups[signature].append(i)

    representatives = []
    cluster_map = [-1] * len(texts)
    cid = 0

    for idxs in groups.values():
        # El representante es el texto mÃ¡s largo del grupo (mÃ¡s completo)
        longest_idx = max(idxs, key=lambda i: len(texts[i]))
        representatives.append(texts[longest_idx])

        for i in idxs:
            cluster_map[i] = cid
        cid += 1

    print(f"âœ… {len(texts)} noticias â†’ {len(representatives)} grupos Ãºnicos")
    return representatives, np.array(cluster_map)

def analyze_universal(rep_text, client_name):
    """AnÃ¡lisis MEJORADO con lÃ³gica de contexto"""
    lower = rep_text.lower()
    client_lower = client_name.lower()

    # === ANÃLISIS DE TONO CON PRIORIDADES ===

    # PRIORIDAD 1: Negativos directos contra el cliente
    negative_about_client = any(
        f"{neg} {client_lower}" in lower or f"{client_lower} {neg}" in lower
        for neg in ["investigan al", "denuncian al", "acusan", "escÃ¡ndalo", "corrupciÃ³n"]
    )

    if negative_about_client:
        tono = "Negativo"
        confianza = 0.95

    # PRIORIDAD 2: Reacciones neutras (lamenta, rechaza eventos externos)
    elif any(reaction in lower for reaction in NEUTRAL_REACTIONS):
        # Si solo reacciona a eventos externos = Neutro
        # (no es gestiÃ³n propia, solo declaraciones)
        tono = "Neutro"
        confianza = 0.88

    # PRIORIDAD 3: GestiÃ³n positiva del cliente
    else:
        # Buscar si el cliente ES EL GESTOR (sujeto activo)
        is_active_subject = False

        # Contexto 1: "liderazgo del alcalde X", "gracias a X"
        leadership_patterns = [
            f"liderazgo del {client_lower}",
            f"liderazgo de {client_lower}",
            f"gracias a {client_lower}",
            f"gracias al {client_lower}",
            f"gestiÃ³n del {client_lower}",
            f"gestiÃ³n de {client_lower}"
        ]

        if any(pattern in lower for pattern in leadership_patterns):
            is_active_subject = True

        # Contexto 2: "alcalde X + verbo de gestiÃ³n activa"
        if not is_active_subject:
            active_verbs = ["confirma", "anuncia", "inaugura", "entrega", "invierte",
                          "construye", "lidera", "impulsa", "gestiona", "inicia"]

            for verb in active_verbs:
                # PatrÃ³n: "alcalde X verbo"
                if f"alcalde {client_lower} {verb}" in lower or \
                   f"alcaldÃ­a {verb}" in lower:
                    is_active_subject = True
                    break

        # Contexto 3: Logros/resultados de programas (implican gestiÃ³n)
        # "500 bachilleres inician...", "familias beneficiadas..."
        has_achievement = any(indicator in lower for indicator in ACHIEVEMENT_INDICATORS)

        # Contexto 4: Presencia de indicadores positivos generales
        has_positive_context = any(ctx in lower for ctx in POSITIVE_CONTEXTS)

        # Si hay logros concretos en Ã¡reas de gestiÃ³n pÃºblica = Positivo
        if is_active_subject or has_positive_context or has_achievement:
            tono = "Positivo"
            confianza = 0.92 if is_active_subject else 0.85
        else:
            tono = "Neutro"
            confianza = 0.70

    # === ANÃLISIS DE TEMA ===
    tema = "GestiÃ³n y Acciones"  # Por defecto
    max_matches = 0

    for topic, keywords in TOPICS_KEYWORDS.items():
        matches = sum(1 for kw in keywords if kw in lower)
        if matches > max_matches:
            max_matches = matches
            tema = topic

    return tono, round(confianza, 3), tema

# ==================== MAIN EXECUTION ====================
print("\n" + "="*80)
print("ğŸ“° ANALIZADOR DE NOTICIAS v30 - CLUSTERING REAL")
print("="*80 + "\n")

# Solicitar nombre del cliente
client_name = input("ğŸ‘¤ Nombre del cliente (ej: Carlos Pinedo): ").strip()
if not client_name:
    client_name = "Carlos Pinedo"
    print(f"   Usando cliente por defecto: {client_name}")

# Cargar archivo
print("\nğŸ“‚ Sube tu archivo Excel...")
uploaded = files.upload()
file_name = list(uploaded.keys())[0]

# Leer datos
print(f"ğŸ“– Leyendo {file_name}...")
df = pd.read_excel(file_name)

# Detectar columna de texto
text_columns = ['resumen', 'texto', 'contenido', 'titulo', 'title', 'noticia', 'descripcion']
text_col = next((c for c in text_columns if c in df.columns), None)

if not text_col:
    print(f"âŒ Error: No se encontrÃ³ columna de texto. Columnas disponibles: {list(df.columns)}")
    raise ValueError("No se encontrÃ³ columna de texto vÃ¡lida")

print(f"âœ… Columna detectada: '{text_col}'")

# Limpiar datos
df = df.dropna(subset=[text_col]).reset_index(drop=True)
texts = df[text_col].astype(str).tolist()
print(f"ğŸ“Š {len(texts)} noticias cargadas\n")

# ==================== PROCESAMIENTO ====================
t0 = time.time()

# Clustering REAL
rep_texts, cluster_map = universal_cluster(texts)

# AnÃ¡lisis - CADA GRUPO SE ANALIZA UNA SOLA VEZ
print("\nğŸ” Analizando tono y tema de grupos Ãºnicos...")
tonos = []
confianzas = []
temas = []

for rep in tqdm(rep_texts, desc="Procesando"):
    tono, conf, tema = analyze_universal(rep, client_name)
    tonos.append(tono)
    confianzas.append(conf)
    temas.append(tema)

# Mapear resultados - TODAS las noticias del mismo grupo tendrÃ¡n EXACTAMENTE el mismo tema/tono
print("\nğŸ”— Aplicando tema/tono a grupos similares...")
df["grupo_id"] = cluster_map
df["tono_marca"] = [tonos[cluster_map[i]] for i in range(len(df))]
df["confianza"] = [confianzas[cluster_map[i]] for i in range(len(df))]
df["tema"] = [temas[cluster_map[i]] for i in range(len(df))]

# VerificaciÃ³n: Mostrar algunos grupos para debugging
print("\nğŸ” Verificando grupos (muestra):")
for gid in sorted(df["grupo_id"].unique())[:3]:
    grupo = df[df["grupo_id"] == gid]
    if len(grupo) > 1:
        print(f"\n   Grupo {gid} ({len(grupo)} noticias) - Tono: {tonos[gid]} - Tema: {temas[gid]}")
        for idx, row in grupo.head(2).iterrows():
            texto_corto = row[text_col][:80] + "..." if len(row[text_col]) > 80 else row[text_col]
            print(f"      â€¢ {texto_corto}")

# ==================== EXPORTACIÃ“N (SOLO 1 HOJA) ====================
out = f"Final_{client_name.replace(' ', '_')}_{time.strftime('%Y%m%d_%H%M')}.xlsx"
print(f"\nğŸ’¾ Guardando resultados en {out}...")

# SOLO UNA HOJA con todos los resultados
df.to_excel(out, sheet_name="Resultados", index=False, engine="openpyxl")

files.download(out)

# ==================== RESULTADOS ====================
tiempo_total = time.time() - t0
print(f"\n{'='*80}")
print(f"âœ… Â¡ANÃLISIS COMPLETADO!")
print(f"â±ï¸  Tiempo: {tiempo_total:.1f}s")
print(f"ğŸ“„ Archivo: {out}")
print(f"{'='*80}\n")

# EstadÃ­sticas
total = len(df)
pos = (df["tono_marca"] == "Positivo").sum()
neg = (df["tono_marca"] == "Negativo").sum()
neu = (df["tono_marca"] == "Neutro").sum()

print("ğŸ“Š RESUMEN:\n")
print(f"   ğŸ“ˆ Total noticias: {total}")
print(f"   ğŸ”¢ Grupos Ãºnicos: {len(rep_texts)}")
print(f"   ğŸ”— Promedio noticias/grupo: {total/len(rep_texts):.1f}")
print(f"   âœ… Positivas: {pos} ({pos/total*100:.1f}%)")
print(f"   âŒ Negativas: {neg} ({neg/total*100:.1f}%)")
print(f"   âšª Neutras: {neu} ({neu/total*100:.1f}%)")

# Mostrar algunos ejemplos de agrupaciÃ³n
print("\nğŸ“‹ EJEMPLOS DE AGRUPACIÃ“N:")
grupos_multi = df[df.duplicated(subset=["grupo_id"], keep=False)].sort_values("grupo_id")
if len(grupos_multi) > 0:
    for gid in grupos_multi["grupo_id"].unique()[:2]:
        grupo = df[df["grupo_id"] == gid]
        print(f"\n   ğŸ”— Grupo {gid} â†’ {len(grupo)} noticias similares")
        print(f"      Tono asignado: {grupo.iloc[0]['tono_marca']}")
        print(f"      Tema asignado: {grupo.iloc[0]['tema']}")
        for idx, row in grupo.head(2).iterrows():
            texto_corto = row[text_col][:70] + "..." if len(row[text_col]) > 70 else row[text_col]
            print(f"      â€¢ {texto_corto}")
else:
    print("   â„¹ï¸  No se encontraron noticias duplicadas en esta muestra")

print("\nğŸ“ˆ DISTRIBUCIÃ“N DE TONO:")
print(df["tono_marca"].value_counts().to_string())

print("\nğŸ¯ DISTRIBUCIÃ“N DE TEMAS:")
print(df["tema"].value_counts().to_string())

print("\nâœ¨ AnÃ¡lisis finalizado exitosamente âœ¨")
