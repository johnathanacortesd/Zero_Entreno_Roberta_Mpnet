# 游 Analizador de Tono y Tema para Noticias (v15)

Un pipeline avanzado de NLP para clasificar el tono (sentimiento) y el tema de grandes vol칰menes de texto, optimizado para el contexto de noticias en espa침ol.

[![Abrir en Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1vFgoU5bkl3OLJ7PIjQZlSEznJdfDANnS?usp=sharing#scrollTo=f9f36a86)

Este script toma un archivo Excel, procesa una columna de texto (ej. resumen), y devuelve un reporte detallado con:

- **Tono:** Positivo, Negativo o Neutro.

- **Tema:** Una categor칤a fija (ej. "Pol칤tica y Gobierno", "Econom칤a y Finanzas").

- **Agrupamiento:** Identifica noticias duplicadas o sem치nticamente id칠nticas para optimizar el an치lisis y la visualizaci칩n.

## 游댧 Metodolog칤a: El Pipeline de An치lisis

El script opera en un pipeline de varias fases, dise침ado para maximizar tanto la velocidad como la precisi칩n contextual.

1.  **Carga y Limpieza:**

    - Lee un archivo .xlsx subido por el usuario.

    - Normaliza y limpia los textos de la columna resumen (clean\_text\_enhanced), prepar치ndolos para el an치lisis.

2.  **Fase 1: Agrupamiento Inteligente (Clustering)**

    - **Prop칩sito:** Evitar analizar miles de noticias id칠nticas o muy similares. Si 500 art칤culos son un re-post de la misma noticia, solo se analiza *una vez*.

    - **Nivel 1 (Firma):** Agrupa textos por sus primeras 8 palabras. Es un filtro r치pido para encontrar duplicados exactos.

    - **Nivel 2 (Sem치ntico):** Dentro de cada grupo de "firma", un modelo de embeddings (paraphrase-multilingual-mpnet-base-v2) vectoriza los textos. Un clustering jer치rquico (AgglomerativeClustering o DBSCAN) agrupa textos que *significan* lo mismo aunque est칠n escritos de forma diferente.

    - **Nivel 3 (Fusi칩n):** Compara los textos "representantes" de cada cluster y fusiona micro-clusters que son sem치nticamente id칠nticos.

3.  **Fase 2: An치lisis de Tono (H칤brido)**

    - Se procesan 칰nicamente los textos "representantes" de cada cluster.

    - **L칩gica Base:** El modelo clapAI/roberta-large-multilingual-sentiment da una clasificaci칩n inicial (Positivo, Negativo, Neutro).

    - **L칩gica de Patrones:** El texto tambi칠n se compara con un diccionario de patrones (SENTIMENT\_PATTERNS) que contienen palabras con alta carga sentimental (ej. tragedia, crisis grave, logro hist칩rico).

    - **Decisi칩n Final:** Se implementa una l칩gica de votaci칩n. Para noticias individuales, se da **prioridad al resultado de los patrones** (si no es neutro), ya que estos son m치s sensibles al contexto de noticias que el modelo general.

4.  **Fase 3: Clasificaci칩n de Tema (Jer치rquica)**

    - **Nivel 1 (Keywords):** El texto se compara primero con el diccionario TOPIC\_KEYWORDS. Si encuentra coincidencias fuertes (ej. "presidente petro" o "reforma pensional"), asigna el tema "Pol칤tica y Gobierno" con alta confianza. Esto es r치pido y muy preciso.

    - **Nivel 2 (Sem치ntico):** Si no hay un match claro por keywords, se usan los embeddings del modelo paraphrase-multilingual-mpnet-base-v2. Se compara la similitud sem치ntica del texto con "centroides" (frases clave) de cada tema y se asigna el m치s cercano.

5.  **Fase 4: Post-procesamiento y Consistencia**

    - El script revisa los resultados en busca de inconsistencias l칩gicas.

    - **Ejemplo:** Si un art칤culo fue clasificado como "Positivo" pero el tema es "Seguridad y Justicia" (y contiene palabras como masacre o asesinato), el script lo corrige autom치ticamente a "Neutro" o "Negativo".

6.  **Fase 5: Exportaci칩n**

    - Los resultados (tono y tema) del cluster representante se propagan a todos los textos que pertenecen a ese cluster.

    - Se genera un archivo Excel (analisis\_avanzado\_v15\_...xlsx) con los resultados detallados, estad칤sticas y m칠tricas de rendimiento.

## 游 Modelos Utilizados y Ventajas

La elecci칩n de los modelos es crucial para el contexto de noticias en espa침ol.

### Para Tono: clapAI/roberta-large-multilingual-sentiment

- **쯈u칠 es?** Es un modelo RoBERTa-large entrenado en 8 idiomas (incluyendo espa침ol) y afinado (fine-tuned) espec칤ficamente para la tarea de clasificaci칩n de sentimientos.

- **Ventajas para Noticias en Espa침ol:**

    1.  **Multiling칲e Nativo:** A diferencia de modelos solo en ingl칠s traducidos, este fue entrenado con texto en espa침ol desde el inicio, capturando mejor las sutilezas, modismos y estructuras gramaticales del idioma.

    2.  **Arquitectura "Large":** Al ser un modelo large, tiene una comprensi칩n contextual m치s profunda que los modelos base, permiti칠ndole entender mejor la iron칤a o el sentimiento complejo en frases largas de noticias.

    3.  **H칤brido con Patrones:** El script no conf칤a ciegamente en el modelo. Al combinarlo con los SENTIMENT\_PATTERNS (que fueron ajustados para ser m치s sensibles), se obtiene lo mejor de ambos mundos: la comprensi칩n contextual del modelo y la precisi칩n expl칤cita de las palabras clave.

### Para Temas (Clustering y Sem치ntica): sentence-transformers/paraphrase-multilingual-mpnet-base-v2

- **쯈u칠 es?** Es un modelo MPNet (una evoluci칩n de BERT) parte de la familia SentenceTransformers. Est치 dise침ado para una tarea espec칤fica: crear "embeddings" (vectores num칠ricos) que representan el significado de una oraci칩n.

- **Ventajas para Noticias en Espa침ol:**

    1.  **Especialista en Par치frasis:** Este modelo fue entrenado espec칤ficamente para identificar **par치frasis** (frases que significan lo mismo). Esto es *perfecto* para las noticias, donde "El gobierno anuncia nueva reforma" y "Ejecutivo presenta proyecto de ley" son sem치nticamente id칠nticos. El modelo los agrupar치 correctamente.

    2.  **Eficiencia Sem치ntica:** Genera vectores de alta calidad que son excelentes para comparar similitud (clustering). Esto permite al script encontrar textos tem치ticamente similares incluso si no comparten *ninguna* palabra clave.

    3.  **Multiling칲e:** Al igual que RoBERTa, su naturaleza multiling칲e garantiza un alto rendimiento en espa침ol.

## 游꿢 La Necesidad de Temas Fijos y Palabras Clave

Este script utiliza un enfoque de **clasificaci칩n supervisada (temas fijos)** en lugar de un enfoque no supervisado (como *Topic Modeling* tipo LDA, que "descubre" temas).

**쯇or qu칠 es esto una ventaja?**

1.  **Consistencia del Negocio:** Para el an치lisis de medios, la consistencia es clave. Los analistas necesitan "contenedores" estables. Si un modelo "descubre" el tema "F칰tbol" un d칤a y "Deportes de Bal칩n" al siguiente, los reportes no son comparables. Los temas fijos (Pol칤tica, Econom칤a, Deportes) garantizan que los datos siempre est칠n organizados de la misma manera.

2.  **Contextualizaci칩n (Dominio Espec칤fico):** Un modelo de IA general no sabe que "ELN", "disidencias FARC" o "paz total" son temas de "Seguridad y Justicia" en Colombia. Tampoco sabe que "presidente petro" o "reforma pensional" son "Pol칤tica y Gobierno".

    - El diccionario TOPIC\_KEYWORDS **inyecta este conocimiento de dominio espec칤fico** (el contexto colombiano) directamente en el pipeline.

3.  **Precisi칩n y Velocidad (Enfoque Jer치rquico):** El sistema de palabras clave (primary y secondary) es extremadamente r치pido. El script lo usa como un "filtro de alta confianza".

    - Si un texto contiene "inflaci칩n" y "banco rep칰blica", se clasifica instant치neamente como "Econom칤a".

    - Esto permite que el modelo de embeddings (que es m치s lento) solo se utilice en los textos ambiguos que no activaron ninguna palabra clave, optimizando el rendimiento general.

## 游 C칩mo Usar

1.  **Entorno:** Aseg칰rese de estar en un entorno con GPU (como Google Colab) para un rendimiento 칩ptimo.

2.  **Instalaci칩n:** Instale las dependencias necesarias:

    ```bash

    pip install torch pandas numpy tqdm transformers sentence-transformers scikit-learn openpyxl

    ```

3.  **Ejecuci칩n:** Corra el script `analizador_v15.py` en su entorno.

4.  **Carga:** Cuando se le solicite, suba su archivo Excel. Este archivo **debe** contener una columna llamada `resumen`.

5.  **Descarga:** El script procesar치 todos los textos y autom치ticamente iniciar치 la descarga del archivo de resultados (ej. `analisis_avanzado_v15_...xlsx`).

## 丘뒲잺 Licencias

### Licencia del Script

Este script (`analizador_v15.py`) se distribuye bajo la **Licencia MIT**.

Copyright (c) 2025 [Johnathan Cort칠s]

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

### Licencias de los Modelos Utilizados

Los modelos de Hugging Face utilizados en este proyecto se distribuyen bajo la **Licencia Apache 2.0**:

- clapAI/roberta-large-multilingual-sentiment: [Apache 2.0 License](https://huggingface.co/clapAI/roberta-large-multilingual-sentiment/blob/main/LICENSE)

- sentence-transformers/paraphrase-multilingual-mpnet-base-v2: [Apache 2.0 License](https://huggingface.co/sentence-transformers/paraphrase-multilingual-mpnet-base-v2/blob/master/LICENSE)
